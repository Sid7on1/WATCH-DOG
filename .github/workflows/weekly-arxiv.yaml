name: üöÄ Daily ArXiv AI/ML Paper Implementation Generator

"on":
  schedule:
    - cron: '0 3 * * *'  # Every night at 3:00 AM UTC
  workflow_dispatch:
    inputs:
      max_papers:
        description: 'Maximum number of papers to process'
        required: false
        default: '5'
        type: string
      dry_run:
        description: 'Run in dry-run mode (no repos created)'
        required: false
        default: false
        type: boolean

env:
  PYTHON_VERSION: '3.11'

jobs:
  process-papers:
    name: üöÄ Process ArXiv Papers
    runs-on: ubuntu-latest
    timeout-minutes: 180
    
    steps:
    - name: üì• Checkout Repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.API_GITHUB }}
        fetch-depth: 0
    
    - name: üêç Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: üì¶ Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: üîç Validate Environment
      run: |
        echo "Checking required secrets and files..."
        
        # Check required secrets
        if [ -z "${{ secrets.OPENROUTER_API_KEY }}" ]; then
          echo "::error::OPENROUTER_API_KEY secret is required"
          exit 1
        fi
        if [ -z "${{ secrets.API_GITHUB }}" ]; then
          echo "::error::API_GITHUB secret is required"
          exit 1
        fi
        
        # Check optional fallback key
        if [ -z "${{ secrets.KEY2 }}" ]; then
          echo "::warning::KEY2 secret not set - no fallback API key available"
        else
          echo "‚úÖ Fallback API key (KEY2) configured"
        fi
        
        # Check required files
        if [ ! -f "fix2.py" ]; then
          echo "::error::fix2.py not found"
          exit 1
        fi
        if [ ! -f "advanced_paper_extractor.py" ]; then
          echo "::error::advanced_paper_extractor.py not found"
          exit 1
        fi
        if [ ! -f "requirements.txt" ]; then
          echo "::error::requirements.txt not found"
          exit 1
        fi
        
        echo "‚úÖ All required secrets and files are present"
    
    - name: ‚öôÔ∏è Configure Git
      run: |
        git config --global user.name "M1-Evo-Agent[bot]"
        git config --global user.email "m1-evo-agent@users.noreply.github.com"
    
    - name: üîç Validate Python Scripts
      run: |
        echo "üêç Validating Python script syntax..."
        
        # Check fix2.py syntax
        if python -m py_compile fix2.py; then
          echo "‚úÖ fix2.py syntax is valid"
        else
          echo "::error::fix2.py has syntax errors"
          exit 1
        fi
        
        # Check advanced_paper_extractor.py syntax
        if python -m py_compile advanced_paper_extractor.py; then
          echo "‚úÖ advanced_paper_extractor.py syntax is valid"
        else
          echo "::error::advanced_paper_extractor.py has syntax errors"
          exit 1
        fi
        
        echo "‚úÖ All Python scripts validated successfully"
    
    - name: üìö Fetch and Extract Papers from ArXiv
      run: |
        echo "üöÄ Running ArXiv paper extraction pipeline..."
        
        # Comprehensive AI/ML/DL domains - automatically included every night
        # cs.AI: Artificial Intelligence
        # cs.LG: Machine Learning  
        # cs.CV: Computer Vision
        # cs.CL: Natural Language Processing
        # cs.NE: Neural Networks
        # cs.RO: Robotics
        # cs.HC: Human-Computer Interaction
        # stat.ML: Statistics - Machine Learning
        # cs.IR: Information Retrieval
        # cs.MM: Multimedia
        # cs.SD: Sound Processing
        # cs.DC: Distributed Computing
        # cs.CR: Cryptography and Security
        # cs.IT: Information Theory
        DOMAINS="cs.AI cs.LG cs.CV cs.CL cs.NE cs.RO cs.HC stat.ML cs.IR cs.MM cs.SD cs.DC cs.CR cs.IT"
        MAX_PAPERS="${{ github.event.inputs.max_papers || '5' }}"
        
        echo "üìä Configuration:"
        echo "  - Domains: $DOMAINS"
        echo "  - Max papers: $MAX_PAPERS"
        echo "  - Delay: 8 seconds"
        echo "  - Threshold: 0.7"
        
        if python advanced_paper_extractor.py \
          --arxiv \
          --domains $DOMAINS \
          --max-papers $MAX_PAPERS \
          --delay 8 \
          --threshold 0.7 \
          --verbose; then
          echo "‚úÖ Paper extraction completed successfully"
          
          # Check if papers were extracted
          if [ -d "runs" ] && [ "$(find runs -name '*.json' | wc -l)" -gt 0 ]; then
            PAPER_COUNT=$(find runs -name '*.json' | wc -l)
            echo "üìÑ Extracted $PAPER_COUNT papers"
          else
            echo "‚ö†Ô∏è No papers were extracted - check extraction logs"
          fi
        else
          echo "::error::Paper extraction failed"
          exit 1
        fi
      env:
        OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
        KEY2: ${{ secrets.KEY2 }}
        GITHUB_TOKEN: ${{ secrets.API_GITHUB }}
        GITHUB_USERNAME: "Sid7on1"
    
    - name: üèóÔ∏è Generate Repositories with Dual Saving
      run: |
        echo "üöÄ Generating repositories with dual saving..."
        echo "üì¶ Individual repos + WATCHDOG_memory backups"
        
        CMD_ARGS="--verbose"
        
        if [ "${{ github.event.inputs.dry_run }}" = "true" ]; then
          CMD_ARGS="$CMD_ARGS --dry-run"
          echo "üß™ Running in DRY RUN mode"
        fi
        
        MAX_PAPERS="${{ github.event.inputs.max_papers || '3' }}"
        CMD_ARGS="$CMD_ARGS --max-papers $MAX_PAPERS"
        
        echo "üìä Configuration:"
        echo "  - Max papers: $MAX_PAPERS"
        echo "  - Dry run: ${{ github.event.inputs.dry_run }}"
        echo "  - Primary API key: $([ -n "$OPENROUTER_API_KEY" ] && echo "‚úÖ Set" || echo "‚ùå Missing")"
        echo "  - Fallback API key: $([ -n "$KEY2" ] && echo "‚úÖ Set" || echo "‚ö†Ô∏è Not set")"
        
        echo "üöÄ Running: python fix2.py $CMD_ARGS"
        
        if python fix2.py $CMD_ARGS; then
          echo "‚úÖ Repository generation completed successfully"
          
          # Check results
          if [ -f "managed_repos_state.json" ]; then
            echo "üìä State file created: managed_repos_state.json"
          fi
          
          if [ -d "logs" ]; then
            LOG_COUNT=$(find logs -name "*.log" | wc -l)
            echo "üìù Generated $LOG_COUNT log files"
          fi
        else
          echo "::error::Repository generation failed"
          echo "::error::Check logs for detailed error information"
          
          # Show recent logs for debugging
          if [ -d "logs" ]; then
            echo "üìù Recent log entries:"
            find logs -name "*.log" -exec tail -10 {} \; 2>/dev/null || true
          fi
          
          exit 1
        fi
      env:
        OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
        KEY2: ${{ secrets.KEY2 }}
        GITHUB_TOKEN: ${{ secrets.API_GITHUB }}
        GITHUB_USERNAME: "Sid7on1"
        GITHUB_ACTIONS: "true"
    
    - name: üìä Upload Results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: processing-results-${{ github.run_id }}
        path: |
          logs/
          workspace/
          managed_repos_state.json
          relevant_json/
          relevant_pdfs/
          runs/
        retention-days: 30
        if-no-files-found: warn
    
    - name: üìã Generate Summary Report
      if: always()
      run: |
        echo "üìä Generating execution summary..."
        echo "=================================="
        
        # Check state file
        if [ -f "managed_repos_state.json" ]; then
          echo "‚úÖ Repository processing completed"
          echo "üìÑ State file: managed_repos_state.json"
          
          # Try to extract summary from state file
          if command -v jq >/dev/null 2>&1; then
            REPO_COUNT=$(jq 'length' managed_repos_state.json 2>/dev/null || echo "unknown")
            echo "üì¶ Repositories processed: $REPO_COUNT"
          fi
        else
          echo "‚ö†Ô∏è No state file found - check logs for details"
        fi
        
        # Check logs
        if [ -d "logs" ]; then
          LOG_COUNT=$(find logs -name "*.log" | wc -l)
          echo "üìù Log files generated: $LOG_COUNT"
          
          # Check for final summary files
          if [ -f "logs/final_summary_"*.json ]; then
            echo "üìä Final summary available"
          fi
          
          if [ -f "logs/processing_report_"*.md ]; then
            echo "üìã Processing report available"
          fi
        fi
        
        # Check extracted papers
        if [ -d "runs" ]; then
          PAPER_COUNT=$(find runs -name "*.json" | wc -l)
          echo "üìÑ Papers extracted: $PAPER_COUNT"
        fi
        
        # Environment info
        echo ""
        echo "üîß Environment:"
        echo "  - Python version: $(python --version)"
        echo "  - Timestamp: $(date -u)"
        echo "  - Workflow: ${{ github.workflow }}"
        echo "  - Run ID: ${{ github.run_id }}"
        
        echo ""
        echo "‚úÖ Summary generation completed"
    
    - name: üßπ Cleanup Temporary Files
      if: always()
      run: |
        echo "üßπ Cleaning up temporary files..."
        
        # List what we're about to clean
        echo "üìÅ Temporary directories to clean:"
        ls -la | grep -E "(extraction_cache|__pycache__|\.pyc)" || echo "  No temporary files found"
        
        # Clean up
        rm -rf extraction_cache/ || true
        rm -rf __pycache__/ || true
        find . -name "*.pyc" -delete || true
        find . -name "*.pyo" -delete || true
        find . -name "__pycache__" -type d -exec rm -rf {} + || true
        
        echo "‚úÖ Cleanup completed"
    
    - name: üì¢ Workflow Status Notification
      if: always()
      run: |
        echo "üì¢ M1-Evo Agent Workflow Status"
        echo "================================"
        
        if [ "${{ job.status }}" = "success" ]; then
          echo "‚úÖ Workflow completed successfully!"
          echo "üéâ New research repositories have been generated"
        elif [ "${{ job.status }}" = "failure" ]; then
          echo "‚ùå Workflow failed"
          echo "üîç Check the logs above for error details"
        else
          echo "‚ö†Ô∏è Workflow completed with status: ${{ job.status }}"
        fi
        
        echo ""
        echo "üìä Workflow Details:"
        echo "  - Run ID: ${{ github.run_id }}"
        echo "  - Triggered by: ${{ github.event_name }}"
        echo "  - Repository: ${{ github.repository }}"
        echo "  - Branch: ${{ github.ref_name }}"
        echo "  - Timestamp: $(date -u)"

  cleanup-artifacts:
    name: üßπ Cleanup Old Artifacts
    runs-on: ubuntu-latest
    needs: [process-papers]
    if: always()
    
    steps:
    - name: üßπ Clean up old artifacts
      uses: actions/github-script@v7
      with:
        script: |
          const artifacts = await github.rest.actions.listArtifactsForRepo({
            owner: context.repo.owner,
            repo: context.repo.repo,
          });
          
          const thirtyDaysAgo = new Date();
          thirtyDaysAgo.setDate(thirtyDaysAgo.getDate() - 30);
          
          let deletedCount = 0;
          for (const artifact of artifacts.data.artifacts) {
            const createdAt = new Date(artifact.created_at);
            if (createdAt < thirtyDaysAgo) {
              console.log(`Deleting old artifact: ${artifact.name}`);
              await github.rest.actions.deleteArtifact({
                owner: context.repo.owner,
                repo: context.repo.repo,
                artifact_id: artifact.id,
              });
              deletedCount++;
            }
          }
          
          console.log(`Cleaned up ${deletedCount} old artifacts`);
