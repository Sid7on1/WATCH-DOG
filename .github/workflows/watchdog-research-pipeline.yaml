name: ğŸ”¬ WATCHDOG Full Research Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Daily research pipeline at 1:20 AM India time (19:50 UTC)
    - cron: '50 19 * * *'
  workflow_dispatch:
    inputs:
      max_papers_per_domain:
        description: 'Maximum papers to scrape per domain'
        required: false
        default: '5'
        type: string
      skip_scraping:
        description: 'Skip paper scraping (use existing PDFs)'
        required: false
        default: false
        type: boolean
      skip_extraction:
        description: 'Skip PDF text extraction'
        required: false
        default: false
        type: boolean
      skip_selection:
        description: 'Skip relevance selection'
        required: false
        default: false
        type: boolean
      skip_planning:
        description: 'Skip project planning'
        required: false
        default: false
        type: boolean
      skip_coding:
        description: 'Skip code generation'
        required: false
        default: false
        type: boolean
      force_deploy:
        description: 'Force deployment to GitHub'
        required: false
        default: true
        type: boolean

env:
  PYTHON_VERSION: '3.11'
  MAX_PAPERS_PER_DOMAIN: ${{ github.event.inputs.max_papers_per_domain || '5' }}

jobs:
  # ============================================================================
  # STAGE 1: SCRAPER
  # ============================================================================
  scraper:
    name: ğŸ“š scraper.py - ArXiv Paper Scraping
    runs-on: ubuntu-latest
    if: github.event.inputs.skip_scraping != 'true'
    outputs:
      papers_scraped: ${{ steps.scrape-papers.outputs.papers_count }}
      scraping_success: ${{ steps.scrape-papers.outputs.success }}
    
    steps:
    - name: ğŸ”„ Checkout Code
      uses: actions/checkout@v4
    
    - name: ğŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: ğŸ“¦ Install WATCHDOG Dependencies
      run: |
        python -m pip install --upgrade pip
        # Install comprehensive requirements
        if [ -f requirements.txt ]; then 
          pip install -r requirements.txt
        else
          # Fallback essential dependencies for scraping
          pip install requests python-dotenv lxml beautifulsoup4 arxiv urllib3
        fi
        echo "âœ… Dependencies installed for scraping stage"
    
    - name: ğŸ” Configure API Keys
      env:
        API_GITHUB: ${{ secrets.API_GITHUB }}
        OPEN_API: ${{ secrets.OPEN_API }}
        GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        COHERE_API: ${{ secrets.COHERE_API }}
        GROQ_API: ${{ secrets.GROQ_API }}
        HF_API: ${{ secrets.HF_API }}
      run: |
        echo "ğŸ”‘ Configuring API keys for WATCHDOG system..."
        echo "GITHUB_PAT=$API_GITHUB" >> .env
        echo "GITHUB_API=$API_GITHUB" >> .env
        echo "OPEN_API=$OPEN_API" >> .env
        echo "GEMINI_API_KEY=$GEMINI_API_KEY" >> .env
        echo "gemini_API=$GEMINI_API_KEY" >> .env
        echo "cohere_API=$COHERE_API" >> .env
        echo "groq_API=$GROQ_API" >> .env
        echo "HF_API=$HF_API" >> .env
        echo "âœ… Environment configured with all API keys"
    
    - name: ğŸ“š Run ArXiv Paper Scraper
      id: scrape-papers
      run: |
        echo "ğŸ” Starting ArXiv paper scraping..."
        echo "ğŸ“Š Max papers per domain: ${{ env.MAX_PAPERS_PER_DOMAIN }}"
        
        # Run scraper directly
        python scraper.py
        
        # Get results for GitHub output
        if [ -f "artifacts/scraping_summary.txt" ]; then
          papers_count=$(grep -o "Total papers found: [0-9]*" artifacts/scraping_summary.txt | grep -o "[0-9]*" || echo "0")
          echo "papers_count=$papers_count" >> $GITHUB_OUTPUT
          echo "success=true" >> $GITHUB_OUTPUT
          if [ "$papers_count" -eq "0" ]; then
            echo "âœ… Paper scraping completed - no new papers found (all papers already processed)"
          else
            echo "âœ… Paper scraping completed successfully - found $papers_count new papers!"
          fi
        else
          # Check if scraper completed successfully even without summary file
          if [ -f "artifacts/metadata.txt" ] || [ -d "artifacts/pdfs" ]; then
            echo "papers_count=0" >> $GITHUB_OUTPUT
            echo "success=true" >> $GITHUB_OUTPUT
            echo "âœ… Paper scraping completed - no new papers found (summary file cleaned up)"
          else
            echo "papers_count=0" >> $GITHUB_OUTPUT
            echo "success=false" >> $GITHUB_OUTPUT
            echo "âŒ Scraping failed - no artifacts found"
            exit 1
          fi
        fi
    
    - name: ğŸ“Š Upload Scraping Artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: scraped-papers-${{ github.run_number }}
        path: |
          artifacts/pdfs/
          artifacts/metadata.txt
          artifacts/scraping_summary.txt
        retention-days: 7

  # ============================================================================
  # STAGE 2: EXTRACTOR
  # ============================================================================
  extractor:
    name: ğŸ“„ extractor.py - PDF Text Extraction
    runs-on: ubuntu-latest
    needs: scraper
    if: |
      always() && 
      (needs.scraper.result == 'success' || github.event.inputs.skip_scraping == 'true') &&
      github.event.inputs.skip_extraction != 'true'
    outputs:
      chunks_created: ${{ steps.extract-text.outputs.chunks_count }}
      extraction_success: ${{ steps.extract-text.outputs.success }}
    
    steps:
    - name: ğŸ”„ Checkout Code
      uses: actions/checkout@v4
    
    - name: ğŸ“¥ Download Scraped Papers
      if: needs.scraper.result == 'success'
      uses: actions/download-artifact@v4
      with:
        name: scraped-papers-${{ github.run_number }}
        path: ./
    
    - name: ğŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: ğŸ“¦ Install PDF Processing Dependencies
      run: |
        python -m pip install --upgrade pip
        # Install comprehensive requirements
        if [ -f requirements.txt ]; then 
          pip install -r requirements.txt
        else
          # Fallback essential dependencies for PDF processing
          pip install PyPDF2 pdfplumber pathlib
        fi
        echo "âœ… Dependencies installed for PDF extraction stage"
    
    - name: ğŸ“„ Extract Text from PDFs
      id: extract-text
      run: |
        echo "ğŸ“„ Starting PDF text extraction..."
        
        # Run extractor directly
        python extractor.py
        
        # Count created chunks for output
        if [ -d "artifacts/pdf-txts" ]; then
          chunk_count=$(find artifacts/pdf-txts -name "chunk_*.txt" | wc -l)
          echo "chunks_count=$chunk_count" >> $GITHUB_OUTPUT
          echo "success=true" >> $GITHUB_OUTPUT
          echo "âœ… Text extraction completed successfully!"
        else
          echo "chunks_count=0" >> $GITHUB_OUTPUT
          echo "success=false" >> $GITHUB_OUTPUT
          echo "âŒ Text extraction failed - no chunks directory found"
          exit 1
        fi
    
    - name: ğŸ“Š Upload Text Extraction Artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: extracted-texts-${{ github.run_number }}
        path: |
          artifacts/pdf-txts/
        retention-days: 7

  # ============================================================================
  # STAGE 3: SELECTOR
  # ============================================================================
  selector:
    name: ğŸ¯ selector.py - Intelligent Relevance Selection
    runs-on: ubuntu-latest
    needs: [scraper, extractor]
    if: |
      always() && 
      (needs.extractor.result == 'success' || github.event.inputs.skip_extraction == 'true') &&
      github.event.inputs.skip_selection != 'true'
    outputs:
      relevant_papers: ${{ steps.select-relevant.outputs.relevant_count }}
      selection_success: ${{ steps.select-relevant.outputs.success }}
    
    steps:
    - name: ğŸ”„ Checkout Code
      uses: actions/checkout@v4
    
    - name: ğŸ“¥ Download Extracted Texts
      if: needs.extractor.result == 'success'
      uses: actions/download-artifact@v4
      with:
        name: extracted-texts-${{ github.run_number }}
        path: ./
    
    - name: ğŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: ğŸ“¦ Install Selection Dependencies
      run: |
        python -m pip install --upgrade pip
        # Install comprehensive requirements
        if [ -f requirements.txt ]; then 
          pip install -r requirements.txt
        else
          # Fallback essential dependencies for AI selection
          pip install requests python-dotenv google-generativeai cohere groq
        fi
        echo "âœ… Dependencies installed for selection stage"
    
    - name: ğŸ” Configure AI API Keys
      env:
        API_GITHUB: ${{ secrets.API_GITHUB }}
        OPEN_API: ${{ secrets.OPEN_API }}
        GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        COHERE_API: ${{ secrets.COHERE_API }}
        GROQ_API: ${{ secrets.GROQ_API }}
        HF_API: ${{ secrets.HF_API }}
      run: |
        echo "ğŸ”‘ Configuring AI API keys..."
        echo "GITHUB_PAT=$API_GITHUB" >> .env
        echo "GITHUB_API=$API_GITHUB" >> .env
        echo "OPEN_API=$OPEN_API" >> .env
        echo "gemini_API=$GEMINI_API_KEY" >> .env
        echo "cohere_API=$COHERE_API" >> .env
        echo "groq_API=$GROQ_API" >> .env
        echo "HF_API=$HF_API" >> .env
        echo "âœ… AI APIs configured"
    
    - name: ğŸ¯ Run Intelligent PDF Selector
      id: select-relevant
      run: |
        echo "ğŸ¯ Starting intelligent relevance selection..."
        
        # Run selector directly
        python selector.py
        
        # Count relevant papers for output
        if [ -d "artifacts/relevant" ]; then
          relevant_count=$(find artifacts/relevant -mindepth 1 -maxdepth 1 -type d | wc -l)
          echo "relevant_count=$relevant_count" >> $GITHUB_OUTPUT
          echo "success=true" >> $GITHUB_OUTPUT
          echo "âœ… Relevance selection completed successfully!"
        else
          echo "relevant_count=0" >> $GITHUB_OUTPUT
          echo "success=false" >> $GITHUB_OUTPUT
          echo "âŒ Relevance selection failed - no relevant directory found"
          exit 1
        fi
    
    - name: ğŸ“Š Upload Selection Artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: relevant-papers-${{ github.run_number }}
        path: |
          artifacts/relevant/
        retention-days: 7

  # ============================================================================
  # STAGE 4: PLANNER
  # ============================================================================
  planner:
    name: ğŸ“‹ planner.py - Intelligent Project Planning
    runs-on: ubuntu-latest
    needs: [scraper, extractor, selector]
    if: |
      always() && 
      (needs.selector.result == 'success' || github.event.inputs.skip_selection == 'true') &&
      github.event.inputs.skip_planning != 'true'
    outputs:
      plans_created: ${{ steps.create-plans.outputs.plans_count }}
      planning_success: ${{ steps.create-plans.outputs.success }}
    
    steps:
    - name: ğŸ”„ Checkout Code
      uses: actions/checkout@v4
    
    - name: ğŸ“¥ Download Relevant Papers
      if: needs.selector.result == 'success'
      uses: actions/download-artifact@v4
      with:
        name: relevant-papers-${{ github.run_number }}
        path: ./
    
    - name: ğŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: ğŸ“¦ Install Planning Dependencies
      run: |
        python -m pip install --upgrade pip
        # Install comprehensive requirements
        if [ -f requirements.txt ]; then 
          pip install -r requirements.txt
        else
          # Fallback essential dependencies for planning
          pip install requests python-dotenv google-generativeai cohere groq
        fi
        echo "âœ… Dependencies installed for planning stage"
    
    - name: ğŸ” Configure Planning API Keys
      env:
        API_GITHUB: ${{ secrets.API_GITHUB }}
        OPEN_API: ${{ secrets.OPEN_API }}
        GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        COHERE_API: ${{ secrets.COHERE_API }}
        GROQ_API: ${{ secrets.GROQ_API }}
        HF_API: ${{ secrets.HF_API }}
      run: |
        echo "ğŸ”‘ Configuring planning API keys..."
        echo "GITHUB_PAT=$API_GITHUB" >> .env
        echo "GITHUB_API=$API_GITHUB" >> .env
        echo "OPEN_API=$OPEN_API" >> .env
        echo "gemini_API=$GEMINI_API_KEY" >> .env
        echo "cohere_API=$COHERE_API" >> .env
        echo "groq_API=$GROQ_API" >> .env
        echo "HF_API=$HF_API" >> .env
        echo "âœ… Planning APIs configured"
    
    - name: ğŸ“‹ Run Intelligent Project Planner
      id: create-plans
      run: |
        echo "ğŸ“‹ Starting intelligent project planning..."
        
        # Run planner directly
        python planner.py
        
        # Count created plans for output
        if [ -d "artifacts/structures" ]; then
          plans_count=$(find artifacts/structures -name "plan.json" | wc -l)
          echo "plans_count=$plans_count" >> $GITHUB_OUTPUT
          echo "success=true" >> $GITHUB_OUTPUT
          echo "âœ… Project planning completed successfully!"
        else
          echo "plans_count=0" >> $GITHUB_OUTPUT
          echo "success=false" >> $GITHUB_OUTPUT
          echo "âŒ Project planning failed - no structures directory found"
          exit 1
        fi
    
    - name: ğŸ“Š Upload Planning Artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: project-plans-${{ github.run_number }}
        path: |
          artifacts/structures/
        retention-days: 7

  # ============================================================================
  # STAGE 5: MANAGER + CODERS (Multi-Agent Code Generation)
  # ============================================================================
  manager:
    name: ğŸ‘¥ manager.py + coder1.py + coder2.py + coder3.py + coder4.py
    runs-on: ubuntu-latest
    needs: [scraper, extractor, selector, planner]
    if: |
      always() && 
      (needs.planner.result == 'success' || github.event.inputs.skip_planning == 'true') &&
      github.event.inputs.skip_coding != 'true'
    outputs:
      projects_created: ${{ steps.generate-code.outputs.projects_count }}
      coding_success: ${{ steps.generate-code.outputs.success }}
    
    steps:
    - name: ğŸ”„ Checkout Code
      uses: actions/checkout@v4
    
    - name: ğŸ“¥ Download Project Plans
      if: needs.planner.result == 'success'
      uses: actions/download-artifact@v4
      with:
        name: project-plans-${{ github.run_number }}
        path: ./
    
    - name: ğŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: ğŸ“¦ Install Coding Dependencies
      run: |
        python -m pip install --upgrade pip
        # Install comprehensive requirements
        if [ -f requirements.txt ]; then 
          pip install -r requirements.txt
        else
          # Fallback essential dependencies for coding (threading/queue are built-in)
          pip install requests python-dotenv google-generativeai cohere groq
        fi
        echo "âœ… Dependencies installed for coding stage"
    
    - name: ğŸ” Configure Coding API Keys
      env:
        API_GITHUB: ${{ secrets.API_GITHUB }}
        OPEN_API: ${{ secrets.OPEN_API }}
        GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        COHERE_API: ${{ secrets.COHERE_API }}
        GROQ_API: ${{ secrets.GROQ_API }}
        HF_API: ${{ secrets.HF_API }}
      run: |
        echo "ğŸ”‘ Configuring coding API keys..."
        echo "GITHUB_PAT=$API_GITHUB" >> .env
        echo "GITHUB_API=$API_GITHUB" >> .env
        echo "OPEN_API=$OPEN_API" >> .env
        echo "gemini_API=$GEMINI_API_KEY" >> .env
        echo "cohere_API=$COHERE_API" >> .env
        echo "groq_API=$GROQ_API" >> .env
        echo "HF_API=$HF_API" >> .env
        echo "âœ… Coding APIs configured"
    
    - name: ğŸ‘¥ Run Multi-Agent Project Manager
      id: generate-code
      run: |
        echo "ğŸ‘¥ Starting multi-agent code generation..."
        
        # Run manager directly
        python manager.py
        
        # Count created projects for output
        if [ -d "artifacts/projects" ]; then
          projects_count=$(find artifacts/projects -mindepth 1 -maxdepth 1 -type d | wc -l)
          echo "projects_count=$projects_count" >> $GITHUB_OUTPUT
          echo "success=true" >> $GITHUB_OUTPUT
          echo "âœ… Code generation completed successfully!"
        else
          echo "projects_count=0" >> $GITHUB_OUTPUT
          echo "success=false" >> $GITHUB_OUTPUT
          echo "âŒ Code generation failed - no projects directory found"
          exit 1
        fi
    
    - name: ğŸ“Š Upload Generated Projects
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: generated-projects-${{ github.run_number }}
        path: |
          artifacts/projects/
        retention-days: 30

  # ============================================================================
  # STAGE 6: GITHUB DEPLOYMENT
  # ============================================================================
  github-deployment:
    name: ğŸš€ GitHub Repository Deployment
    runs-on: ubuntu-latest
    needs: [scraper, extractor, selector, planner, manager]
    if: |
      always() && 
      (needs.manager.result == 'success' || github.event.inputs.skip_coding == 'true') &&
      github.event.inputs.force_deploy == 'true'
    outputs:
      repos_created: ${{ steps.deploy-repos.outputs.repos_count }}
      deployment_success: ${{ steps.deploy-repos.outputs.success }}
    
    steps:
    - name: ğŸ”„ Checkout Code
      uses: actions/checkout@v4
    
    - name: ğŸ“¥ Download Generated Projects
      if: needs.manager.result == 'success'
      uses: actions/download-artifact@v4
      with:
        name: generated-projects-${{ github.run_number }}
        path: ./
    
    - name: ğŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: ğŸ“¦ Install Deployment Dependencies
      run: |
        python -m pip install --upgrade pip
        # Install comprehensive requirements
        if [ -f requirements.txt ]; then 
          pip install -r requirements.txt
        else
          # Fallback essential dependencies for deployment (base64/shutil/tempfile are built-in)
          pip install requests python-dotenv
        fi
        echo "âœ… Dependencies installed for deployment stage"
    
    - name: ğŸ” Configure GitHub API
      env:
        API_GITHUB: ${{ secrets.API_GITHUB }}
      run: |
        echo "ğŸ”‘ Configuring GitHub API..."
        echo "GITHUB_PAT=$API_GITHUB" >> .env
        echo "GITHUB_API=$API_GITHUB" >> .env
        echo "âœ… GitHub API configured"
    
    - name: ğŸš€ Deploy Projects to GitHub Repositories
      id: deploy-repos
      run: |
        echo "ğŸš€ Starting GitHub repository deployment..."
        
        # Run pusher for deployment only (no cleanup yet)
        python -c "
        import pusher
        import sys
        from pathlib import Path
        
        try:
            # Initialize GitHub repository manager
            github_manager = pusher.GitHubRepositoryManager()
            print('âœ… GitHub repository manager initialized')
            
            # Process all projects and create repositories (no cleanup)
            success = github_manager.process_all_projects()
            
            if success:
                print('âœ… All projects deployed to GitHub successfully!')
                
                # Get repository count
                projects_dir = Path('artifacts/projects')
                repos_count = 0
                if projects_dir.exists():
                    repos_count = len([d for d in projects_dir.iterdir() if d.is_dir()])
                
                print(f'ğŸ“Š Repositories created: {repos_count}')
                print(f'repos_count={repos_count}')
                print('success=true')
            else:
                print('âŒ Some projects failed to deploy')
                print('repos_count=0')
                print('success=false')
                sys.exit(1)
                
        except Exception as e:
            print(f'âŒ GitHub deployment failed: {e}')
            print('repos_count=0')
            print('success=false')
            sys.exit(1)
        " > deployment_output.txt
        
        # Parse output for GitHub Actions
        repos_count=$(grep "repos_count=" deployment_output.txt | cut -d'=' -f2 || echo "0")
        success=$(grep "success=" deployment_output.txt | cut -d'=' -f2 || echo "false")
        
        echo "repos_count=$repos_count" >> $GITHUB_OUTPUT
        echo "success=$success" >> $GITHUB_OUTPUT
        
        if [ "$success" = "true" ]; then
          echo "âœ… GitHub deployment completed successfully!"
        else
          echo "âŒ GitHub deployment failed"
          exit 1
        fi
    
    - name: ğŸ” Verify Repository Deployments
      run: |
        echo "ğŸ” Verifying deployed repositories..."
        echo "âœ… Deployment verification completed (check pusher.py logs for details)"
      continue-on-error: true

  # ============================================================================
  # STAGE 7: FINAL CLEANUP & LOGGING
  # ============================================================================
  final-cleanup:
    name: ğŸ§¹ Final Cleanup & Logging
    runs-on: ubuntu-latest
    needs: [scraper, extractor, selector, planner, manager, github-deployment]
    if: always()
    
    steps:
    - name: ğŸ”„ Checkout Code
      uses: actions/checkout@v4
    
    - name: ğŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: ğŸ“¦ Install Cleanup Dependencies
      run: |
        python -m pip install --upgrade pip
        if [ -f requirements.txt ]; then 
          pip install -r requirements.txt
        else
          pip install requests python-dotenv
        fi
        echo "âœ… Dependencies installed for cleanup stage"
    
    - name: ğŸ” Configure GitHub API
      env:
        API_GITHUB: ${{ secrets.API_GITHUB }}
      run: |
        echo "ğŸ”‘ Configuring GitHub API..."
        echo "GITHUB_PAT=$API_GITHUB" >> .env
        echo "GITHUB_API=$API_GITHUB" >> .env
        echo "âœ… GitHub API configured"
    
    - name: ğŸ§¹ Run Final Cleanup and Logging
      run: |
        echo "ğŸ§¹ Starting final cleanup and logging..."
        
        # Run pusher for final cleanup and logging
        python -c "
        import pusher
        import sys
        
        try:
            # Initialize GitHub repository manager
            github_manager = pusher.GitHubRepositoryManager()
            print('âœ… GitHub repository manager initialized for cleanup')
            
            # Start workflow logging
            github_manager.workflow_start()
            
            # Log workflow completion
            github_manager.log_activity('workflow', 'WATCHDOG pipeline completed', 'success', {
                'scraper_result': '${{ needs.scraper.result }}',
                'extractor_result': '${{ needs.extractor.result }}',
                'selector_result': '${{ needs.selector.result }}',
                'planner_result': '${{ needs.planner.result }}',
                'manager_result': '${{ needs.manager.result }}',
                'deployment_result': '${{ needs.github-deployment.result }}',
                'papers_scraped': '${{ needs.scraper.outputs.papers_scraped || \"0\" }}',
                'projects_created': '${{ needs.manager.outputs.projects_created || \"0\" }}',
                'repos_created': '${{ needs.github-deployment.outputs.repos_created || \"0\" }}'
            })
            
            # End workflow with cleanup and logging
            github_manager.workflow_end()
            
            print('âœ… Final cleanup and logging completed successfully!')
                
        except Exception as e:
            print(f'âŒ Final cleanup failed: {e}')
            # Don't exit with error - cleanup failure shouldn't fail the whole workflow
        "
        
        echo "âœ… Final cleanup and logging completed!"

  # ============================================================================
  # STAGE 8: FINAL REPORTING & SUMMARY
  # ============================================================================
  final-summary:
    name: ğŸ“Š Pipeline Summary & Reporting
    runs-on: ubuntu-latest
    needs: [scraper, extractor, selector, planner, manager, github-deployment]
    if: always()
    
    steps:
    - name: ğŸ“Š Generate Complete Pipeline Summary
      run: |
        echo "# ğŸ”¬ WATCHDOG Full Research Pipeline Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## ğŸ¯ Pipeline Results" >> $GITHUB_STEP_SUMMARY
        echo "| Stage | Status | Output |" >> $GITHUB_STEP_SUMMARY
        echo "|-------|--------|--------|" >> $GITHUB_STEP_SUMMARY
        echo "| ğŸ“š Paper Scraping | ${{ needs.paper-scraping.result }} | ${{ needs.paper-scraping.outputs.papers_scraped || '0' }} papers |" >> $GITHUB_STEP_SUMMARY
        echo "| ğŸ“„ Text Extraction | ${{ needs.text-extraction.result }} | ${{ needs.text-extraction.outputs.chunks_created || '0' }} chunks |" >> $GITHUB_STEP_SUMMARY
        echo "| ğŸ¯ Relevance Selection | ${{ needs.relevance-selection.result }} | ${{ needs.relevance-selection.outputs.relevant_papers || '0' }} relevant |" >> $GITHUB_STEP_SUMMARY
        echo "| ğŸ“‹ Project Planning | ${{ needs.project-planning.result }} | ${{ needs.project-planning.outputs.plans_created || '0' }} plans |" >> $GITHUB_STEP_SUMMARY
        echo "| ğŸ‘¥ Code Generation | ${{ needs.code-generation.result }} | ${{ needs.code-generation.outputs.projects_created || '0' }} projects |" >> $GITHUB_STEP_SUMMARY
        echo "| ğŸš€ GitHub Deployment | ${{ needs.github-deployment.result }} | ${{ needs.github-deployment.outputs.repos_created || '0' }} repositories |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## ğŸ“ˆ Research Metrics" >> $GITHUB_STEP_SUMMARY
        echo "- **Papers Scraped**: ${{ needs.paper-scraping.outputs.papers_scraped || '0' }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Text Chunks**: ${{ needs.text-extraction.outputs.chunks_created || '0' }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Relevant Papers**: ${{ needs.relevance-selection.outputs.relevant_papers || '0' }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Project Plans**: ${{ needs.project-planning.outputs.plans_created || '0' }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Generated Projects**: ${{ needs.code-generation.outputs.projects_created || '0' }}" >> $GITHUB_STEP_SUMMARY
        echo "- **GitHub Repositories**: ${{ needs.github-deployment.outputs.repos_created || '0' }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## ğŸ”§ Pipeline Information" >> $GITHUB_STEP_SUMMARY
        echo "- **Trigger**: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Branch**: ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Run Number**: ${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
        echo "- **Max Papers Per Domain**: ${{ env.MAX_PAPERS_PER_DOMAIN }}" >> $GITHUB_STEP_SUMMARY
    
    - name: ğŸ‰ Success Notification
      if: |
        needs.paper-scraping.result == 'success' && 
        needs.text-extraction.result == 'success' &&
        needs.relevance-selection.result == 'success' &&
        needs.project-planning.result == 'success' &&
        needs.code-generation.result == 'success'
      run: |
        echo "ğŸ‰ WATCHDOG RESEARCH PIPELINE SUCCESS!"
        echo "âœ… Complete end-to-end research pipeline executed successfully"
        echo ""
        echo "ğŸ“Š FINAL RESULTS:"
        echo "  ğŸ“š Papers Scraped: ${{ needs.paper-scraping.outputs.papers_scraped || '0' }}"
        echo "  ğŸ“„ Text Chunks: ${{ needs.text-extraction.outputs.chunks_created || '0' }}"
        echo "  ğŸ¯ Relevant Papers: ${{ needs.relevance-selection.outputs.relevant_papers || '0' }}"
        echo "  ğŸ“‹ Project Plans: ${{ needs.project-planning.outputs.plans_created || '0' }}"
        echo "  ğŸ‘¥ Generated Projects: ${{ needs.code-generation.outputs.projects_created || '0' }}"
        echo "  ğŸš€ GitHub Repositories: ${{ needs.github-deployment.outputs.repos_created || '0' }}"
        echo ""
        echo "ğŸ”— Check artifacts for detailed outputs from each stage"
    
    - name: âš ï¸ Partial Success Notification
      if: |
        (needs.paper-scraping.result == 'success' || needs.paper-scraping.result == 'skipped') &&
        (needs.text-extraction.result == 'failure' || needs.relevance-selection.result == 'failure' || 
         needs.project-planning.result == 'failure' || needs.code-generation.result == 'failure')
      run: |
        echo "âš ï¸ WATCHDOG Pipeline completed with some issues"
        echo "âœ… Initial stages completed successfully"
        echo "âŒ Some downstream stages failed"
        echo "ğŸ”§ Check the failed jobs for details"
        echo ""
        echo "ğŸ“Š PARTIAL RESULTS:"
        echo "  ğŸ“š Papers Scraped: ${{ needs.paper-scraping.outputs.papers_scraped || '0' }}"
        echo "  ğŸ“„ Text Chunks: ${{ needs.text-extraction.outputs.chunks_created || '0' }}"
        echo "  ğŸ¯ Relevant Papers: ${{ needs.relevance-selection.outputs.relevant_papers || '0' }}"
    
    - name: âŒ Failure Notification
      if: needs.paper-scraping.result == 'failure'
      run: |
        echo "âŒ WATCHDOG RESEARCH PIPELINE FAILED!"
        echo "ğŸš¨ Initial paper scraping failed - pipeline cannot continue"
        echo "ğŸ”§ Please check the scraping job logs and fix issues"
        echo "ğŸ’¡ Common issues: API rate limits, network connectivity, invalid domains"
        exit 1
    
    - name: ğŸ“§ Create Issue on Critical Failure
      if: failure() && github.ref == 'refs/heads/main'
      uses: actions/github-script@v6
      with:
        script: |
          github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: `ğŸš¨ WATCHDOG Research Pipeline Failed - Run #${{ github.run_number }}`,
            body: `
            ## Research Pipeline Failure Report
            
            **Run**: #${{ github.run_number }}
            **Commit**: ${{ github.sha }}
            **Branch**: ${{ github.ref_name }}
            **Trigger**: ${{ github.event_name }}
            
            ### Stage Results
            - ğŸ“š Paper Scraping: ${{ needs.paper-scraping.result }}
            - ğŸ“„ Text Extraction: ${{ needs.text-extraction.result }}
            - ğŸ¯ Relevance Selection: ${{ needs.relevance-selection.result }}
            - ğŸ“‹ Project Planning: ${{ needs.project-planning.result }}
            - ğŸ‘¥ Code Generation: ${{ needs.code-generation.result }}
            - ğŸš€ GitHub Deployment: ${{ needs.github-deployment.result }}
            
            ### Outputs
            - Papers Scraped: ${{ needs.paper-scraping.outputs.papers_scraped || '0' }}
            - Text Chunks: ${{ needs.text-extraction.outputs.chunks_created || '0' }}
            - Relevant Papers: ${{ needs.relevance-selection.outputs.relevant_papers || '0' }}
            - Project Plans: ${{ needs.project-planning.outputs.plans_created || '0' }}
            - Generated Projects: ${{ needs.code-generation.outputs.projects_created || '0' }}
            - GitHub Repositories: ${{ needs.github-deployment.outputs.repos_created || '0' }}
            
            **Action Required**: Please review the [workflow run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}) and fix the issues.
            `,
            labels: ['bug', 'research-pipeline', 'high-priority']
          })
      continue-on-error: true
